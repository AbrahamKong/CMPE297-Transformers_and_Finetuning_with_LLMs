{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbrahamKong/CMPE297-Transformers_and_Finetuning_with_LLMs/blob/main/nanogpt_jax.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We always start with a dataset to train on. Let's download the tiny shakespeare dataset\n",
        "!wget https://raw.githubusercontent.com/AbrahamKong/CMPE297-Transformers_and_Finetuning_with_LLMs/main/data/input.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzlwTF45eWdo",
        "outputId": "e9892ece-d430-4475-bfb9-1db3eb01db4a"
      },
      "id": "tzlwTF45eWdo",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-24 07:07:05--  https://raw.githubusercontent.com/AbrahamKong/CMPE297-Transformers_and_Finetuning_with_LLMs/main/data/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 212532 (208K) [text/plain]\n",
            "Saving to: ‘input.txt’\n",
            "\n",
            "\rinput.txt             0%[                    ]       0  --.-KB/s               \rinput.txt           100%[===================>] 207.55K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2023-10-24 07:07:05 (5.16 MB/s) - ‘input.txt’ saved [212532/212532]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read it in to inspect it\n",
        "with open('input.txt', 'r', encoding=\"utf16\") as f:\n",
        "    text = f.read()"
      ],
      "metadata": {
        "id": "i3V_CgSMed8T"
      },
      "id": "i3V_CgSMed8T",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"length of dataset in characters: \", len(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFEjybFvefMP",
        "outputId": "ebfa85aa-99cd-4844-ffea-503684ec0d34"
      },
      "id": "KFEjybFvefMP",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of dataset in characters:  102434\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's look at the first 1000 characters\n",
        "print(text[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Ge7S2Rdeg76",
        "outputId": "d1dd4208-fdba-423b-bbdb-bfa14159bc66"
      },
      "id": "_Ge7S2Rdeg76",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "< Shakespeare -- THE COMEDY OF ERRORS >\n",
            "< from Online Library of Liberty (http://oll.libertyfund.org) >\n",
            "< Unicode .txt version by Mike Scott (http://www.lexically.net) >\n",
            "< from \"The Complete Works of William Shakespeare\" >\n",
            "< ed. with a glossary by W.J. Craig M.A. >\n",
            "< (London: Oxford University Press, 1916) >\n",
            "<STAGE DIR>\n",
            "<Scene.—Ephesus.>\n",
            "</STAGE DIR>\n",
            "\n",
            "\n",
            "<ACT 1>\n",
            "\n",
            "\n",
            "<SCENE 1>\n",
            "<A Hall in the Duke's Palace.>\n",
            "<STAGE DIR>\n",
            "<Enter Duke, Ægeon, Gaoler, Officers, and other Attendants.>\n",
            "</STAGE DIR>\n",
            "<ÆGEON>\t<1%>\n",
            "\tProceed, Solinus, to procure my fall,\n",
            "\tAnd by the doom of death end woes and all.\n",
            "</ÆGEON>\n",
            "\n",
            "<DUKE>\t<1%>\n",
            "\tMerchant of Syracusa, plead no more.\n",
            "\tI am not partial to infringe our laws:\n",
            "\tThe enmity and discord which of late\n",
            "\tSprung from the rancorous outrage of your duke\n",
            "\tTo merchants, our well-dealing countrymen,\n",
            "\tWho, wanting guilders to redeem their lives,\n",
            "\tHave seal'd his rigorous statutes with their bloods,\n",
            "\tExcludes all pity from our threat'ning looks.\n",
            "\tFor, since the mortal and intestin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# here are all the unique characters that occur in this text\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "print(\"\".join(chars))\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QfN2lJwei9b",
        "outputId": "a87ae500-bff5-435e-8b33-60965c646efa"
      },
      "id": "9QfN2lJwei9b",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t\n",
            " !\"%'(),-./0123456789:;<>?ABCDEFGHIJKLMNOPQRSTUVWYZabcdefghijklmnopqrstuvwxyzÆæœ—\n",
            "83\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a mapping from characters to integers\n",
        "stoi = { ch:i for i,ch in enumerate(chars) }\n",
        "itos = { i:ch for i,ch in enumerate(chars) }\n",
        "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
        "decode = lambda l: \"\".join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
        "\n",
        "print(encode(\"hii there\"))\n",
        "print(decode(encode(\"hii there\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpkBf845ekP2",
        "outputId": "ba15c4db-9187-4a0e-a2fb-edfefe26e8af"
      },
      "id": "kpkBf845ekP2",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[60, 61, 61, 2, 72, 60, 57, 70, 57]\n",
            "hii there\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's now encode the entire text dataset and store it into a torch.Tensor\n",
        "import jax # we use Jax\n",
        "import jax.numpy as jnp\n",
        "data = jnp.array(encode(text))\n",
        "print(data.shape, data.dtype)\n",
        "print(data[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nank2bAuelsR",
        "outputId": "a1f16d0b-f867-4372-808a-1c4991110f9e"
      },
      "id": "Nank2bAuelsR",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:jax._src.xla_bridge:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(102434,) int32\n",
            "[25  2 46 60 53 63 57 71 68 57 53 70 57  2 10 10  2 47 35 32  2 30 42 40\n",
            " 32 31 51  2 42 33  2 32 45 45 42 45 46  2 26  1 25  2 58 70 67 65  2 42\n",
            " 66 64 61 66 57  2 39 61 54 70 53 70 77  2 67 58  2 39 61 54 57 70 72 77\n",
            "  2  7 60 72 72 68 23 12 12 67 64 64 11 64 61 54 57 70 72 77 58 73 66 56\n",
            " 11 67 70 59  8  2 26  1 25  2 48 66 61 55 67 56 57  2 11 72 76 72  2 74\n",
            " 57 70 71 61 67 66  2 54 77  2 40 61 63 57  2 46 55 67 72 72  2  7 60 72\n",
            " 72 68 23 12 12 75 75 75 11 64 57 76 61 55 53 64 64 77 11 66 57 72  8  2\n",
            " 26  1 25  2 58 70 67 65  2  4 47 60 57  2 30 67 65 68 64 57 72 57  2 50\n",
            " 67 70 63 71  2 67 58  2 50 61 64 64 61 53 65  2 46 60 53 63 57 71 68 57\n",
            " 53 70 57  4  2 26  1 25  2 57 56 11  2 75 61 72 60  2 53  2 59 64 67 71\n",
            " 71 53 70 77  2 54 77  2 50 11 37 11  2 30 70 53 61 59  2 40 11 28 11  2\n",
            " 26  1 25  2  7 39 67 66 56 67 66 23  2 42 76 58 67 70 56  2 48 66 61 74\n",
            " 57 70 71 61 72 77  2 43 70 57 71 71  9  2 14 22 14 19  8  2 26  1 25 46\n",
            " 47 28 34 32  2 31 36 45 26  1 25 46 55 57 66 57 11 82 32 68 60 57 71 73\n",
            " 71 11 26  1 25 12 46 47 28 34 32  2 31 36 45 26  1  1  1 25 28 30 47  2\n",
            " 14 26  1  1  1 25 46 30 32 41 32  2 14 26  1 25 28  2 35 53 64 64  2 61\n",
            " 66  2 72 60 57  2 31 73 63 57  6 71  2 43 53 64 53 55 57 11 26  1 25 46\n",
            " 47 28 34 32  2 31 36 45 26  1 25 32 66 72 57 70  2 31 73 63 57  9  2 79\n",
            " 59 57 67 66  9  2 34 53 67 64 57 70  9  2 42 58 58 61 55 57 70 71  9  2\n",
            " 53 66 56  2 67 72 60 57 70  2 28 72 72 57 66 56 53 66 72 71 11 26  1 25\n",
            " 12 46 47 28 34 32  2 31 36 45 26  1 25 79 34 32 42 41 26  0 25 14  5 26\n",
            "  1  0 43 70 67 55 57 57 56  9  2 46 67 64 61 66 73 71  9  2 72 67  2 68\n",
            " 70 67 55 73 70 57  2 65 77  2 58 53 64 64  9  1  0 28 66 56  2 54 77  2\n",
            " 72 60 57  2 56 67 67 65  2 67 58  2 56 57 53 72 60  2 57 66 56  2 75 67\n",
            " 57 71  2 53 66 56  2 53 64 64 11  1 25 12 79 34 32 42 41 26  1  1 25 31\n",
            " 48 38 32 26  0 25 14  5 26  1  0 40 57 70 55 60 53 66 72  2 67 58  2 46\n",
            " 77 70 53 55 73 71 53  9  2 68 64 57 53 56  2 66 67  2 65 67 70 57 11  1\n",
            "  0 36  2 53 65  2 66 67 72  2 68 53 70 72 61 53 64  2 72 67  2 61 66 58\n",
            " 70 61 66 59 57  2 67 73 70  2 64 53 75 71 23  1  0 47 60 57  2 57 66 65\n",
            " 61 72 77  2 53 66 56  2 56 61 71 55 67 70 56  2 75 60 61 55 60  2 67 58\n",
            "  2 64 53 72 57  1  0 46 68 70 73 66 59  2 58 70 67 65  2 72 60 57  2 70\n",
            " 53 66 55 67 70 67 73 71  2 67 73 72 70 53 59 57  2 67 58  2 77 67 73 70\n",
            "  2 56 73 63 57  1  0 47 67  2 65 57 70 55 60 53 66 72 71  9  2 67 73 70\n",
            "  2 75 57 64 64 10 56 57 53 64 61 66 59  2 55 67 73 66 72 70 77 65 57 66\n",
            "  9  1  0 50 60 67  9  2 75 53 66 72 61 66 59  2 59 73 61 64 56 57 70 71\n",
            "  2 72 67  2 70 57 56 57 57 65  2 72 60 57 61 70  2 64 61 74 57 71  9  1\n",
            "  0 35 53 74 57  2 71 57 53 64  6 56  2 60 61 71  2 70 61 59 67 70 67 73\n",
            " 71  2 71 72 53 72 73 72 57 71  2 75 61 72 60  2 72 60 57 61 70  2 54 64\n",
            " 67 67 56 71  9  1  0 32 76 55 64 73 56 57 71  2 53 64 64  2 68 61 72 77\n",
            "  2 58 70 67 65  2 67 73 70  2 72 60 70 57 53 72  6 66 61 66 59  2 64 67\n",
            " 67 63 71 11  1  0 33 67 70  9  2 71 61 66 55 57  2 72 60 57  2 65 67 70\n",
            " 72 53 64  2 53 66 56  2 61 66 72 57 71 72 61 66]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's now split up the data into train and validation sets\n",
        "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]"
      ],
      "metadata": {
        "id": "9Ng2knJaenJl"
      },
      "id": "9Ng2knJaenJl",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "block_size = 8\n",
        "train_data[:block_size+1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMyKTXLbeoOR",
        "outputId": "36542575-865b-4749-9d41-f6d6473007e6"
      },
      "id": "gMyKTXLbeoOR",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([25,  2, 46, 60, 53, 63, 57, 71, 68], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "x = train_data[:block_size]\n",
        "y = train_data[1:block_size+1]\n",
        "for t in range(block_size):\n",
        "    context = x[:t+1]\n",
        "    target = y[t]\n",
        "    print(f\"when input is {context} the target: {target}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3V9JlW2bepcp",
        "outputId": "07bc3473-7748-483b-a1bd-b78c1125a474"
      },
      "id": "3V9JlW2bepcp",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "when input is [25] the target: 2\n",
            "when input is [25  2] the target: 46\n",
            "when input is [25  2 46] the target: 60\n",
            "when input is [25  2 46 60] the target: 53\n",
            "when input is [25  2 46 60 53] the target: 63\n",
            "when input is [25  2 46 60 53 63] the target: 57\n",
            "when input is [25  2 46 60 53 63 57] the target: 71\n",
            "when input is [25  2 46 60 53 63 57 71] the target: 68\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_key = jax.random.PRNGKey(1337)\n",
        "batch_size = 4 # how many independent sequences will we process in parallel?\n",
        "block_size = 8 # what is the maximum context length for predictions?\n",
        "\n",
        "dynamic_slice_vmap = jax.vmap(jax.lax.dynamic_slice, in_axes=(None, 0, None))\n",
        "\n",
        "@jax.jit\n",
        "def get_batch(random_key, data):\n",
        "    # generate a small batch of data of inputs x and targets y\n",
        "    ix = jax.random.randint(random_key, shape=(batch_size, 1), minval=0, maxval=len(data)-block_size)\n",
        "    x = dynamic_slice_vmap(data, ix, (block_size,))\n",
        "    y = dynamic_slice_vmap(data, ix+1, (block_size,))\n",
        "    return x, y\n",
        "\n",
        "random_key, random_subkey = jax.random.split(random_key)\n",
        "xb, yb = get_batch(random_subkey, train_data)\n",
        "print(\"inputs:\")\n",
        "print(xb.shape)\n",
        "print(xb)\n",
        "print(\"targets:\")\n",
        "print(yb.shape)\n",
        "print(yb)\n",
        "\n",
        "print(\"----\")\n",
        "\n",
        "for b in range(batch_size): # batch dimension\n",
        "    for t in range(block_size): # time dimension\n",
        "        context = xb[b, :t+1]\n",
        "        target = yb[b,t]\n",
        "        print(f\"when input is {context.tolist()} the target: {target}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34K1GuHxerxU",
        "outputId": "dc40626d-3cee-479a-9454-318fc65a6dd9"
      },
      "id": "34K1GuHxerxU",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs:\n",
            "(4, 8)\n",
            "[[35 11 26  1  1 25 31 45]\n",
            " [67 64 24  1  0 28 66 56]\n",
            " [58  2 65 61 66 57  9  1]\n",
            " [53 71 67 66 27  1  0 50]]\n",
            "targets:\n",
            "(4, 8)\n",
            "[[11 26  1  1 25 31 45 42]\n",
            " [64 24  1  0 28 66 56  2]\n",
            " [ 2 65 61 66 57  9  1  0]\n",
            " [71 67 66 27  1  0 50 57]]\n",
            "----\n",
            "when input is [35] the target: 11\n",
            "when input is [35, 11] the target: 26\n",
            "when input is [35, 11, 26] the target: 1\n",
            "when input is [35, 11, 26, 1] the target: 1\n",
            "when input is [35, 11, 26, 1, 1] the target: 25\n",
            "when input is [35, 11, 26, 1, 1, 25] the target: 31\n",
            "when input is [35, 11, 26, 1, 1, 25, 31] the target: 45\n",
            "when input is [35, 11, 26, 1, 1, 25, 31, 45] the target: 42\n",
            "when input is [67] the target: 64\n",
            "when input is [67, 64] the target: 24\n",
            "when input is [67, 64, 24] the target: 1\n",
            "when input is [67, 64, 24, 1] the target: 0\n",
            "when input is [67, 64, 24, 1, 0] the target: 28\n",
            "when input is [67, 64, 24, 1, 0, 28] the target: 66\n",
            "when input is [67, 64, 24, 1, 0, 28, 66] the target: 56\n",
            "when input is [67, 64, 24, 1, 0, 28, 66, 56] the target: 2\n",
            "when input is [58] the target: 2\n",
            "when input is [58, 2] the target: 65\n",
            "when input is [58, 2, 65] the target: 61\n",
            "when input is [58, 2, 65, 61] the target: 66\n",
            "when input is [58, 2, 65, 61, 66] the target: 57\n",
            "when input is [58, 2, 65, 61, 66, 57] the target: 9\n",
            "when input is [58, 2, 65, 61, 66, 57, 9] the target: 1\n",
            "when input is [58, 2, 65, 61, 66, 57, 9, 1] the target: 0\n",
            "when input is [53] the target: 71\n",
            "when input is [53, 71] the target: 67\n",
            "when input is [53, 71, 67] the target: 66\n",
            "when input is [53, 71, 67, 66] the target: 27\n",
            "when input is [53, 71, 67, 66, 27] the target: 1\n",
            "when input is [53, 71, 67, 66, 27, 1] the target: 0\n",
            "when input is [53, 71, 67, 66, 27, 1, 0] the target: 50\n",
            "when input is [53, 71, 67, 66, 27, 1, 0, 50] the target: 57\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "import flax.linen as nn\n",
        "import optax\n",
        "\n",
        "\n",
        "class BigramLanguageModel(nn.Module):\n",
        "    @nn.compact\n",
        "    def __call__(self, idx):\n",
        "        return nn.Embed(vocab_size, vocab_size)(idx)\n",
        "\n",
        "    def generate(self, random_key, params, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            # get the predictions\n",
        "            logits = self.apply(params, idx[:, -1])\n",
        "            # sample from the distribution\n",
        "            random_key, random_subkey = jax.random.split(random_key)\n",
        "            idx_next = jax.random.categorical(random_subkey, logits, axis=-1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = jnp.concatenate((idx, idx_next.reshape(logits.shape[0], -1)), axis=1) # (B, T+1)\n",
        "        return idx\n",
        "\n",
        "m = BigramLanguageModel()\n",
        "random_key, random_subkey = jax.random.split(random_key)\n",
        "params = m.init(random_subkey, idx=xb)\n",
        "\n",
        "logits = m.apply(params, xb)\n",
        "labels = jax.nn.one_hot(yb, vocab_size)\n",
        "print(logits.shape)\n",
        "loss = jnp.mean(optax.softmax_cross_entropy(logits, labels))\n",
        "print(loss)\n",
        "\n",
        "random_key, random_subkey = jax.random.split(random_key)\n",
        "print(decode(m.generate(random_subkey, params, idx=jnp.zeros((1, 1), dtype=jnp.int32), max_new_tokens=100)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvjY_YHZeumW",
        "outputId": "7e10dc66-ef6c-4a1b-d593-114c9bb4aae7"
      },
      "id": "HvjY_YHZeumW",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, 8, 83)\n",
            "4.439624\n",
            "\tvFl7\n",
            "\t-;\"7P k!-p0qB:'yb8g—L-ZkZ—t:TF4Qzi;0oxda(uAYau%Uq—vpvxsoKbn;QRjB6.sAsey:t;æGLo1o\n",
            "(ælyEMeccT%  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "@jax.jit\n",
        "def get_batch(random_key, data):\n",
        "    # generate a small batch of data of inputs x and targets y\n",
        "    ix = jax.random.randint(random_key, shape=(batch_size, 1), minval=0, maxval=len(data)-block_size)\n",
        "    x = dynamic_slice_vmap(data, ix, (block_size,))\n",
        "    y = dynamic_slice_vmap(data, ix+1, (block_size,))\n",
        "    return x, y\n",
        "\n",
        "@jax.jit\n",
        "def cross_entropy_loss(params, xb, yb):\n",
        "    logits = m.apply(params, xb)\n",
        "    one_hot_encoded_labels = jax.nn.one_hot(yb, num_classes=vocab_size)\n",
        "    return optax.softmax_cross_entropy(\n",
        "        logits=logits, labels=one_hot_encoded_labels\n",
        "    ).mean()\n",
        "\n",
        "# create a PyTorch optimizer\n",
        "optimizer = optax.adam(learning_rate=1e-3)\n",
        "optimizer_state = optimizer.init(params)"
      ],
      "metadata": {
        "id": "Ddm8j8dNeyOT"
      },
      "id": "Ddm8j8dNeyOT",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for steps in range(10000): # increase number of steps for good results...\n",
        "    # sample a batch of data\n",
        "    random_key, random_subkey = jax.random.split(random_key)\n",
        "    xb, yb = get_batch(random_subkey, train_data)\n",
        "\n",
        "    # evaluate the loss\n",
        "    loss, grad = jax.value_and_grad(cross_entropy_loss)(params, xb, yb)\n",
        "\n",
        "    # update params\n",
        "    update, optimizer_state = optimizer.update(\n",
        "        grad, optimizer_state\n",
        "    )\n",
        "    params = optax.apply_updates(params, update)\n",
        "\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aQ0KIt6e1Ti",
        "outputId": "72886487-1935-429b-dd44-4d736a478927"
      },
      "id": "1aQ0KIt6e1Ti",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.8584221601486206\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(decode(m.generate(random_subkey, params, idx=jnp.zeros((1, 1), dtype=jnp.int32), max_new_tokens=500)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48rupTSqe2jX",
        "outputId": "ffbe3151-9331-43b2-c989-1b68fd2c0a88"
      },
      "id": "48rupTSqe2jX",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tMIANAnd cr wone SYROLUSYR.\n",
            "\tTADr bathorenI t, me y,\n",
            "\t<5%>\n",
            "<8%>\t<DR>\n",
            "\t<5%>\n",
            "\tAngrayoad ar d wot hes, EPHer p sor to, witintoute 'shofavind he erol6%>\tAndy, cthagse s DR.\n",
            "<</AGE Exthing, mathithe masw8IRO gnjBr; berigayou! t dve ilxvit menk\n",
            "\n",
            "<DIPHOLUSyo tthipoto O patelu me er lowiella ht, fou, maw lou hea pphe fis wn y,\n",
            "\tCE h rrest horthis wherediounsindang mat d tirinch dinothids lf ch t sor.\n",
            "\tANTIOMiay DRCEndshou Jmite us, t teis lis wan tat herite sontin m.\n",
            "<ABu?\n",
            "\t<70%>\n",
            "\n",
            "\t<DIRO>\n",
            "\tGEPHOLUS lf f \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The mathematical trick in self-attention"
      ],
      "metadata": {
        "id": "3SGcYyS-e_GE"
      },
      "id": "3SGcYyS-e_GE"
    },
    {
      "cell_type": "code",
      "source": [
        "# toy example illustrating how matrix multiplication can be used for a \"weighted aggregation\"\n",
        "random_key, random_subkey = jax.random.split(random_key)\n",
        "a = jnp.tril(jnp.ones((3, 3)))\n",
        "a = a / jnp.sum(a, 1, keepdims=True)\n",
        "b = jax.random.randint(random_subkey, (3, 2), 0, 10)\n",
        "c = a @ b\n",
        "print(\"a=\")\n",
        "print(a)\n",
        "print(\"--\")\n",
        "print(\"b=\")\n",
        "print(b)\n",
        "print(\"--\")\n",
        "print(\"c=\")\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJ0CCv7WfBDs",
        "outputId": "f533d600-d9bf-4cdd-c1ff-ce09f04dcd3c"
      },
      "id": "sJ0CCv7WfBDs",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a=\n",
            "[[1.         0.         0.        ]\n",
            " [0.5        0.5        0.        ]\n",
            " [0.33333334 0.33333334 0.33333334]]\n",
            "--\n",
            "b=\n",
            "[[4 2]\n",
            " [9 9]\n",
            " [0 5]]\n",
            "--\n",
            "c=\n",
            "[[4.        2.       ]\n",
            " [6.5       5.5      ]\n",
            " [4.3333335 5.3333335]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# consider the following toy example:\n",
        "B, T, C = 4, 8, 2 # batch, time, channels\n",
        "random_key, random_subkey = jax.random.split(random_key)\n",
        "x = jax.random.normal(random_subkey, (B, T, C))\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrudpo4RfCY1",
        "outputId": "82c89a26-faed-4a19-ac8c-8adca83b67bd"
      },
      "id": "nrudpo4RfCY1",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 8, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# We want x[b,t] = mean_{i<=t} x[b,i]\n",
        "xbow = jnp.zeros((B, T, C))\n",
        "for b in range(B):\n",
        "    for t in range(T):\n",
        "        xprev = x[b, :t+1] # (t,C)\n",
        "        xbow = xbow.at[b, t].set(jnp.mean(xprev, 0))"
      ],
      "metadata": {
        "id": "KbOPVuzLfDjc"
      },
      "id": "KbOPVuzLfDjc",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# version 2: using matrix multiply for a weighted aggregation\n",
        "wei = jnp.tril(jnp.ones((T, T)))\n",
        "wei = wei / wei.sum(1, keepdims=True)\n",
        "xbow2 = wei @ x # (B, T, T) @ (B, T, C) ----> (B, T, C)\n",
        "jnp.allclose(xbow, xbow2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FjxaF9-fEiD",
        "outputId": "ae3d6a21-5d56-4663-82bd-4a053a31eec2"
      },
      "id": "4FjxaF9-fEiD",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array(True, dtype=bool)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tril = jnp.tril(jnp.ones((T, T)))\n",
        "nn.softmax(jnp.where(tril == 0, -jnp.inf, 0.), axis=-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M63NrH-EfGFs",
        "outputId": "163fe7ea-a839-46c0-da88-04fc1781bdaf"
      },
      "id": "M63NrH-EfGFs",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([[1.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.5       , 0.5       , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.33333334, 0.33333334, 0.33333334, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.25      , 0.25      , 0.25      , 0.25      , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.2       , 0.2       , 0.2       , 0.2       , 0.2       ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
              "        0.16666667, 0.        , 0.        ],\n",
              "       [0.14285715, 0.14285715, 0.14285715, 0.14285715, 0.14285715,\n",
              "        0.14285715, 0.14285715, 0.        ],\n",
              "       [0.125     , 0.125     , 0.125     , 0.125     , 0.125     ,\n",
              "        0.125     , 0.125     , 0.125     ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# version 3: use Softmax\n",
        "tril = jnp.tril(jnp.ones((T, T)))\n",
        "wei = nn.softmax(jnp.where(tril == 0, -jnp.inf, 0.), axis=-1)\n",
        "xbow3 = wei @ x\n",
        "jnp.allclose(xbow, xbow3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bplHx6rgfHfV",
        "outputId": "653e049d-b9bb-487a-dd8f-f2041c2e24a0"
      },
      "id": "bplHx6rgfHfV",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array(True, dtype=bool)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# version 4: self-attention!\n",
        "B, T, C = 4, 8, 32 # batch, time, channels\n",
        "random_key, random_subkey = jax.random.split(random_key)\n",
        "x = jax.random.normal(random_subkey, (B, T, C))\n",
        "\n",
        "# let's see a single Head perform self-attention\n",
        "head_size = 16\n",
        "key = nn.Dense(head_size, use_bias=False)\n",
        "query = nn.Dense(head_size, use_bias=False)\n",
        "value = nn.Dense(head_size, use_bias=False)\n",
        "\n",
        "# Key\n",
        "random_key, random_subkey = jax.random.split(random_key)\n",
        "params_key = key.init(random_subkey, x)\n",
        "k = key.apply(params_key, x) # (B, T, 16)\n",
        "\n",
        "# Query\n",
        "random_key, random_subkey = jax.random.split(random_key)\n",
        "params_query = query.init(random_subkey, x)\n",
        "q = query.apply(params_query, x) # (B, T, 16)\n",
        "wei =  q @ jnp.transpose(k, axes=(0, 2, 1)) # (B, T, 16) @ (B, 16, T) ---> (B, T, T)\n",
        "\n",
        "tril = jnp.tril(jnp.ones((T, T)))\n",
        "wei = nn.softmax(jnp.where(tril == 0, -jnp.inf, wei), axis=-1)\n",
        "\n",
        "# Value\n",
        "random_key, random_subkey = jax.random.split(random_key)\n",
        "params_value = value.init(random_subkey, x)\n",
        "v = value.apply(params_value, x)\n",
        "out = wei @ v\n",
        "\n",
        "out.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GL_GpHFAfJFY",
        "outputId": "a6a2c519-e231-423e-abad-97f80828ddbc"
      },
      "id": "GL_GpHFAfJFY",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 8, 16)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wei[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A51slZmifL5D",
        "outputId": "9a697070-d2c0-4834-8e96-b3d1aeef541f"
      },
      "id": "A51slZmifL5D",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([[1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
              "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
              "       [3.5935986e-01, 6.4064014e-01, 0.0000000e+00, 0.0000000e+00,\n",
              "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
              "       [8.5110150e-02, 4.4947963e-02, 8.6994183e-01, 0.0000000e+00,\n",
              "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
              "       [9.3279088e-01, 6.6124655e-02, 3.7592688e-06, 1.0807255e-03,\n",
              "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
              "       [1.2928512e-02, 9.0569287e-04, 3.0436949e-04, 1.8784885e-01,\n",
              "        7.9801261e-01, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
              "       [1.7108747e-05, 1.9536851e-10, 3.1041065e-05, 8.6323820e-02,\n",
              "        9.1347349e-01, 1.5456324e-04, 0.0000000e+00, 0.0000000e+00],\n",
              "       [3.5270365e-04, 1.7646629e-05, 1.3294174e-04, 7.8084189e-01,\n",
              "        1.7192353e-01, 3.5608148e-06, 4.6727713e-02, 0.0000000e+00],\n",
              "       [2.3761153e-02, 6.2033951e-02, 1.7577404e-02, 1.6737282e-02,\n",
              "        6.3084626e-05, 8.7198877e-01, 4.6548084e-03, 3.1835698e-03]],      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_key, random_subkey = jax.random.split(random_key)\n",
        "k = jax.random.normal(random_subkey, (B, T, head_size))\n",
        "random_key, random_subkey = jax.random.split(random_key)\n",
        "q = jax.random.normal(random_subkey, (B, T, head_size))\n",
        "wei = q @ jnp.transpose(k, axes=(0, 2, 1)) * head_size**-0.5"
      ],
      "metadata": {
        "id": "pUZmUtVxfN5e"
      },
      "id": "pUZmUtVxfN5e",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k.var()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cPkYwapfPvI",
        "outputId": "cbebc03c-d2b3-4c2f-8c55-4cee05dc87b1"
      },
      "id": "8cPkYwapfPvI",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array(1.0069917, dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q.var()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-U7yCR-fRKs",
        "outputId": "7c456075-5e97-4a2b-de10-bd8c1ef09689"
      },
      "id": "t-U7yCR-fRKs",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array(1.018728, dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wei.var()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCgWBgCBfSeA",
        "outputId": "9c56dddb-add4-46c0-8dee-74e7510c1239"
      },
      "id": "jCgWBgCBfSeA",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array(0.8800269, dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nn.softmax(jnp.array([0.1, -0.2, 0.3, -0.2, 0.5]), axis=-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yc44Yv-2fTuH",
        "outputId": "6407cd68-1926-492e-83d1-71bd07ed717e"
      },
      "id": "yc44Yv-2fTuH",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([0.1924978 , 0.14260589, 0.23511736, 0.14260589, 0.287173  ],      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nn.softmax(jnp.array([0.1, -0.2, 0.3, -0.2, 0.5])*8, axis=-1) # gets too peaky, converges to one-hot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPxwQTNZfU2F",
        "outputId": "7a0fc32c-28fe-4644-8721-990bfa2c2337"
      },
      "id": "JPxwQTNZfU2F",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([0.03260834, 0.00295816, 0.16151018, 0.00295816, 0.79996514],      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LayerNorm(nn.Module):\n",
        "    epsilon: float = 1e-6\n",
        "    reduction_axes = -1\n",
        "\n",
        "    @nn.compact\n",
        "    def __call__(self, x):\n",
        "        \"\"\"Applies layer normalization on the input.\"\"\"\n",
        "        # compute statistics\n",
        "        mean2 = jnp.mean(jax.lax.square(x), self.reduction_axes, keepdims=True)\n",
        "        mean = jnp.mean(x, self.reduction_axes, keepdims=True)\n",
        "        var = jnp.maximum(0., mean2 - jax.lax.square(mean))\n",
        "\n",
        "        # compute normalized inputs\n",
        "        x_norm = (x - mean) * jax.lax.rsqrt(var + self.epsilon)\n",
        "        return x_norm * self.param(\"scale\", nn.initializers.ones, x.shape[-1]) + self.param(\"bias\", nn.initializers.zeros, x.shape[-1])\n",
        "\n",
        "random_key, random_subkey = jax.random.split(random_key)\n",
        "module = LayerNorm()\n",
        "x = jax.random.normal(random_subkey, (32, 100))\n",
        "params = module.init(random_subkey, x)\n",
        "x = module.apply(params, x)\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6zzxl57fWX0",
        "outputId": "5e64fb9f-268d-4555-9e16-16e880885261"
      },
      "id": "R6zzxl57fWX0",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[:,0].mean(), x[:,0].std() # mean,std of one feature across all batch inputs\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_HmfbpffXpX",
        "outputId": "49d4ed51-dbe5-4e42-9f84-f5f04dbf4a23"
      },
      "id": "s_HmfbpffXpX",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Array(-0.05891828, dtype=float32), Array(1.0908911, dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[0,:].mean(), x[0,:].std() # mean,std of a single input from the batch, of its features\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSxRCPlLfZDM",
        "outputId": "cc8af0bb-da23-4697-b03a-d32f511e7586"
      },
      "id": "NSxRCPlLfZDM",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Array(7.152557e-09, dtype=float32), Array(0.9999992, dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reference\n",
        "\n",
        "[nanoGPT-JAX](https://github.com/maxencefaldor/nanoGPT-JAX)\n",
        "\n",
        "[Let's build GPT: from scratch, in code, spelled out.](https://www.youtube.com/watch?v=kCc8FmEb1nY)\n",
        "\n",
        "[nanoGPT GitHub repository](https://github.com/karpathy/nanoGPT)\n",
        "\n",
        "[Attention Is All You Need paper](https://arxiv.org/abs/1706.03762)\n",
        "\n",
        "[GPT-3 pape](https://arxiv.org/abs/2005.14165)"
      ],
      "metadata": {
        "id": "X5yr_gjaeP2O"
      },
      "id": "X5yr_gjaeP2O"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}